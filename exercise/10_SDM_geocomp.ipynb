{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-82 14 -59 -21\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "\n",
    "ulx=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\(\",\" \"); print int($2 -3)}')\n",
    "uly=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\)\",\" \"); print int($6 +3)}')\n",
    "lrx=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\(\",\" \"); print int($5 +3)}')\n",
    "lry=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\)\",\" \"); print int($3 -3)}')\n",
    "\n",
    "echo $ulx $uly $lrx $lry\n",
    "\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/cloud/SA_intra.tif  geodata/cloud/SA_intra_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/cloud/SA_meanannual.tif  geodata/cloud/SA_meanannual_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/dem/SA_elevation_mn_GMTED2010_mn.tif  geodata/dem/SA_elevation_mn_GMTED2010_mn_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/vegetation/SA_tree_mn_percentage_GFC2013.tif  geodata/vegetation/SA_tree_mn_percentage_GFC2013_crop.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "# dowload temperature from https://envicloud.wsl.ch/#/?prefix=chelsa%2Fchelsa_V1\n",
    "for MM in 01 02 03 04 05 06 07 08 09 10 11 12 ; do \n",
    "gdal_translate -projwin -82 14 -59 -21 -co COMPRESS=DEFLATE -co ZLEVEL=9     /vsicurl/https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V1/climatologies/tmax/CHELSA_tmax10_${MM}_1979-2013_V1.2_land.tif  geodata/climate/CHELSA_tmax10_${MM}_1979-2013_V1.2_land_crop.tif \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "# calculate mean and stdev for tmax,\n",
    "\n",
    "gdalbuildvrt -overwrite -separate geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt  geodata/climate/CHELSA_tmax10_*_1979-2013_V1.2_land_crop.tif\n",
    "\n",
    "pkstatprofile -co COMPRESS=DEFLATE -co ZLEVEL=9  -nodata -32768 -f  mean -i geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt -o geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop_mean.tif\n",
    "pkstatprofile -co COMPRESS=DEFLATE -co ZLEVEL=9  -nodata -32768 -f stdev -i geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt -o geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop_stdev.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment \n",
    "Proceed with the download also for tmin and prec. Build up the loop and also calculate mean and stdev. pkstatprofile does not very well so insert  gdal_translate to compress. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
