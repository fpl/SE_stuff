{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting environmental predictors for species distribution model\n",
    "\n",
    "One of the first action in Species Distribution Model is to record presence/absence of the species and then search for raster or vector files that store information about environment variables, that define the ecological niche. We will first concentrate on the collection of the environment variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First select a dataset that we can use to define the overall extent of the specie - the study area.\n",
    "We will therefore crop geodata using the species range as an extent and increase of 3 degree in N-S and W-E direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-82 14 -59 -21\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5880, 8400\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "\n",
    "# define north south weast owest extent\n",
    "ulx=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\(\",\" \"); print int($2 -3)}')\n",
    "uly=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\)\",\" \"); print int($6 +3)}')\n",
    "lrx=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\(\",\" \"); print int($5 +3)}')\n",
    "lry=$(ogrinfo -al -so geodata/shp/cartodb-query.shp | grep Extent | awk '{ gsub(\"\\\\)\",\" \"); print int($3 -3)}')\n",
    "\n",
    "## Print the extent to confirm the lat long  \n",
    "echo $ulx $uly $lrx $lry\n",
    "## croping\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/cloud/SA_intra.tif  geodata/cloud/SA_intra_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/cloud/SA_meanannual.tif  geodata/cloud/SA_meanannual_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/dem/SA_elevation_mn_GMTED2010_mn.tif  geodata/dem/SA_elevation_mn_GMTED2010_mn_crop.tif\n",
    "gdal_translate -projwin  $ulx $uly $lrx $lry -co COMPRESS=DEFLATE -co ZLEVEL=9 geodata/vegetation/SA_tree_mn_percentage_GFC2013.tif  geodata/vegetation/SA_tree_mn_percentage_GFC2013_crop.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowonload climate data from https://chelsa-climate.org/ . Using the /vsicurl/ option in gdal is possible to download only the raster extend of your study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 43200, 20880\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "# download temperature from https://envicloud.wsl.ch/#/?prefix=chelsa%2Fchelsa_V1\n",
    "for MM in 01 02 03 04 05 06 07 08 09 10 11 12 ; do \n",
    "gdal_translate -projwin -82 14 -59 -21 -co COMPRESS=DEFLATE -co ZLEVEL=9     /vsicurl/https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V1/climatologies/tmax/CHELSA_tmax10_${MM}_1979-2013_V1.2_land.tif  geodata/climate/CHELSA_tmax10_${MM}_1979-2013_V1.2_land_crop.tif \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annual mean and standard deviation with the monthly values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/selv/SE_data/exercise \n",
    "# calculate mean and stdev for tmax,\n",
    "\n",
    "gdalbuildvrt -overwrite -separate geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt  geodata/climate/CHELSA_tmax10_*_1979-2013_V1.2_land_crop.tif\n",
    "\n",
    "pkstatprofile -co COMPRESS=DEFLATE -co ZLEVEL=9  -nodata -32768 -f  mean -i geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt -o geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop_mean.tif\n",
    "pkstatprofile -co COMPRESS=DEFLATE -co ZLEVEL=9  -nodata -32768 -f stdev -i geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop.vrt -o geodata/climate/CHELSA_tmax10_1979-2013_V1.2_land_crop_stdev.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment \n",
    "## 1) Download and process climate data (grade 20%)\n",
    "Proceed with the download also for tmin and prec. Build up the loop and also calculate mean and stdev. Consider that, pkstatprofile even giving the compression flag (-co COMPRESS=DEFLATE -co ZLEVEL=9) does not compress very well so insert a gdal_translate to perform the compression (and of course remove the intermediate files). \n",
    "## 2) Geomorphometric layers (grade 20%)\n",
    "Using the GMTED2010 DEM (geodata/dem/SA_elevation_mn_GMTED2010_mn_crop.tif) calculate \"aspect\" \"slope\" \"Terrain Ruggedness Index\" using gdal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
